{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0e78443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praw\n",
      "  Downloading praw-7.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.9/site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.9/site-packages (2.0.2)\n",
      "Collecting prawcore<3,>=2.4 (from praw)\n",
      "  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting update_checker>=0.18 (from praw)\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting websocket-client>=0.54.0 (from praw)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in ./.venv/lib/python3.9/site-packages (from prawcore<3,>=2.4->praw) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2025.6.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading praw-7.8.1-py3-none-any.whl (189 kB)\n",
      "Downloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
      "Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: websocket-client, update_checker, prawcore, praw\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [praw]\n",
      "\u001b[1A\u001b[2KSuccessfully installed praw-7.8.1 prawcore-2.4.0 update_checker-0.18.0 websocket-client-1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install praw pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fad201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "061e865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIG ---\n",
    "CLIENT_ID = '3Ptv1n3uzKL-RaqAQnrMlg'\n",
    "CLIENT_SECRET = 'pa5OheU7NtiIw6jl5MaFAz8ouLrZDQ'\n",
    "USER_AGENT = 'reddit-popularity-predictor'\n",
    "\n",
    "SUBREDDITS = ['technology', 'sports', 'funny', 'science', 'politics', 'gaming', 'movies']\n",
    "POSTS_PER_SUBREDDIT = 750\n",
    "SAMPLE_PER_BUCKET = 300 # how many posts per popularity bucket to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75681d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id=CLIENT_ID,\n",
    "    client_secret=CLIENT_SECRET,\n",
    "    user_agent=USER_AGENT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e537529",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_posts(subreddit, sort, limit):\n",
    "    \"\"\"Fetch posts from a subreddit with given sort and limit.\"\"\"\n",
    "    posts = []\n",
    "    submissions = getattr(reddit.subreddit(subreddit), sort)(limit=limit)\n",
    "    for submission in submissions:\n",
    "        posts.append({\n",
    "            'subreddit': subreddit,\n",
    "            'id': submission.id,\n",
    "            'title': submission.title,\n",
    "            'selftext': submission.selftext,\n",
    "            'score': submission.score,\n",
    "            'num_comments': submission.num_comments,\n",
    "            'created_utc': submission.created_utc,\n",
    "            'flair': submission.link_flair_text,\n",
    "            'upvote_ratio': submission.upvote_ratio,\n",
    "            'is_self': submission.is_self,\n",
    "            'nsfw': submission.over_18,\n",
    "            'author': str(submission.author),\n",
    "            'url': submission.url,\n",
    "            'sort_type': sort\n",
    "        })\n",
    "    return posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e66aa375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching new posts from r/technology...\n",
      "Fetching new posts from r/sports...\n",
      "Fetching new posts from r/funny...\n",
      "Fetching new posts from r/science...\n",
      "Fetching new posts from r/politics...\n",
      "Fetching new posts from r/gaming...\n",
      "Fetching new posts from r/movies...\n",
      "Fetching top posts from r/technology...\n",
      "Fetching top posts from r/sports...\n",
      "Fetching top posts from r/funny...\n",
      "Fetching top posts from r/science...\n",
      "Fetching top posts from r/politics...\n",
      "Fetching top posts from r/gaming...\n",
      "Fetching top posts from r/movies...\n",
      "Total posts before bucketing: 10047\n"
     ]
    }
   ],
   "source": [
    "all_posts = []\n",
    "\n",
    "# Fetch new posts (raw, less biased)\n",
    "for sub in SUBREDDITS:\n",
    "    print(f\"Fetching new posts from r/{sub}...\")\n",
    "    all_posts.extend(fetch_posts(sub, 'new', POSTS_PER_SUBREDDIT))\n",
    "\n",
    "# Fetch top posts (popular)\n",
    "for sub in SUBREDDITS:\n",
    "    print(f\"Fetching top posts from r/{sub}...\")\n",
    "    all_posts.extend(fetch_posts(sub, 'top', POSTS_PER_SUBREDDIT))\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(all_posts)\n",
    "\n",
    "# Remove duplicates (some posts may appear in both new and top)\n",
    "df = df.drop_duplicates(subset='id')\n",
    "\n",
    "print(f\"Total posts before bucketing: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72868d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>flair</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>is_self</th>\n",
       "      <th>nsfw</th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>sort_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>technology</td>\n",
       "      <td>1lvds7w</td>\n",
       "      <td>Students can’t use AI to cheat on standardized...</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.752051e+09</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ubcstaffer123</td>\n",
       "      <td>https://www.fraserinstitute.org/commentary/stu...</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>technology</td>\n",
       "      <td>1lvdi5e</td>\n",
       "      <td>Instagram wrongly accuses some users of breach...</td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1.752050e+09</td>\n",
       "      <td>Social Media</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>zsreport</td>\n",
       "      <td>https://www.bbc.com/news/articles/cy8kjdz9nr3o</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>technology</td>\n",
       "      <td>1lvcxoa</td>\n",
       "      <td>Turkey blocks X's Grok chatbot for alleged ins...</td>\n",
       "      <td></td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>1.752047e+09</td>\n",
       "      <td>Social Media</td>\n",
       "      <td>0.91</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>BreakfastTop6899</td>\n",
       "      <td>https://www.reuters.com/business/media-telecom...</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>technology</td>\n",
       "      <td>1lvai0d</td>\n",
       "      <td>GlobalFoundries to make RISC-V CPUs — fab acqu...</td>\n",
       "      <td></td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1.752038e+09</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>0.83</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>jhansonxi</td>\n",
       "      <td>https://www.tomshardware.com/pc-components/cpu...</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>technology</td>\n",
       "      <td>1lv9syt</td>\n",
       "      <td>Rubio impersonation campaign underscores broad...</td>\n",
       "      <td></td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1.752036e+09</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>0.82</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>BreakfastTop6899</td>\n",
       "      <td>https://www.axios.com/2025/07/08/rubio-ai-impe...</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit       id                                              title  \\\n",
       "0  technology  1lvds7w  Students can’t use AI to cheat on standardized...   \n",
       "1  technology  1lvdi5e  Instagram wrongly accuses some users of breach...   \n",
       "2  technology  1lvcxoa  Turkey blocks X's Grok chatbot for alleged ins...   \n",
       "3  technology  1lvai0d  GlobalFoundries to make RISC-V CPUs — fab acqu...   \n",
       "4  technology  1lv9syt  Rubio impersonation campaign underscores broad...   \n",
       "\n",
       "  selftext  score  num_comments   created_utc                    flair  \\\n",
       "0               2             2  1.752051e+09  Artificial Intelligence   \n",
       "1               9             2  1.752050e+09             Social Media   \n",
       "2              18             3  1.752047e+09             Social Media   \n",
       "3              18             1  1.752038e+09                 Hardware   \n",
       "4              25             3  1.752036e+09  Artificial Intelligence   \n",
       "\n",
       "   upvote_ratio  is_self   nsfw            author  \\\n",
       "0          1.00    False  False     ubcstaffer123   \n",
       "1          1.00    False  False          zsreport   \n",
       "2          0.91    False  False  BreakfastTop6899   \n",
       "3          0.83    False  False         jhansonxi   \n",
       "4          0.82    False  False  BreakfastTop6899   \n",
       "\n",
       "                                                 url sort_type  \n",
       "0  https://www.fraserinstitute.org/commentary/stu...       new  \n",
       "1     https://www.bbc.com/news/articles/cy8kjdz9nr3o       new  \n",
       "2  https://www.reuters.com/business/media-telecom...       new  \n",
       "3  https://www.tomshardware.com/pc-components/cpu...       new  \n",
       "4  https://www.axios.com/2025/07/08/rubio-ai-impe...       new  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "848d43b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popularity_bucket\n",
      "high      3415\n",
      "low       3316\n",
      "medium    3316\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Bucket scores into low/medium/high popularity ---\n",
    "\n",
    "# Define buckets by score quantiles or fixed thresholds\n",
    "# Here: Use quantiles to split into 3 equal groups\n",
    "\n",
    "quantiles = df['score'].quantile([0.33, 0.66]).values\n",
    "low_threshold, high_threshold = quantiles[0], quantiles[1]\n",
    "\n",
    "def bucket_score(score):\n",
    "    if score <= low_threshold:\n",
    "        return 'low'\n",
    "    elif score <= high_threshold:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'high'\n",
    "\n",
    "df['popularity_bucket'] = df['score'].apply(bucket_score)\n",
    "\n",
    "print(df['popularity_bucket'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fda28b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the dataset: 10047\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of the dataset:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dde74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skipping as dataset is balanced already\n",
    "# --- Balance dataset by sampling equal posts per bucket ---\n",
    "\n",
    "# balanced_dfs = []\n",
    "\n",
    "# for bucket in ['low', 'medium', 'high']:\n",
    "    # bucket_df = df[df['popularity_bucket'] == bucket]\n",
    "    # sampled_df = bucket_df.sample(n=min(SAMPLE_PER_BUCKET, len(bucket_df)), random_state=42)\n",
    "    # balanced_dfs.append(sampled_df)\n",
    "\n",
    "# balanced_df = pd.concat(balanced_dfs).reset_index(drop=True)\n",
    "\n",
    "# print(f\"Balanced dataset size: {len(balanced_df)}\")\n",
    "# print(balanced_df['popularity_bucket'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcff0c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset to reddit_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Save dataset ---\n",
    "df.to_csv('reddit_dataset.csv', index=False)\n",
    "print(\"Saved dataset to reddit_dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
