{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3bb6a12",
   "metadata": {},
   "source": [
    "# Deep Learning Model - All Features\n",
    "\n",
    "The deep learning model based on a Multilayer Perceptron (MLP) architecture and utilized both textual data (from the post's title and selftext) and categorical metadata (such as subreddit, flair, is_self, and nsfw)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52238c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikeras\n",
      "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\h_ale\\anaconda3\\envs\\cv\\lib\\site-packages (from scikeras) (3.10.0)\n",
      "Requirement already satisfied: scikit-learn>=1.4.2 in c:\\users\\h_ale\\anaconda3\\envs\\cv\\lib\\site-packages (from scikeras) (1.5.1)\n",
      "Requirement already satisfied: absl-py in c:\\users\\h_ale\\anaconda3\\envs\\cv\\lib\\site-packages (from keras>=3.2.0->scikeras) (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\h_ale\\anaconda3\\envs\\cv\\lib\\site-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\h_ale\\anaconda3\\envs\\cv\\lib\\site-packages (from keras>=3.2.0->scikeras) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\h_ale\\anaconda3\\envs\\cv\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.1.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\h_ale\\anaconda3\\envs\\cv\\lib\\site-packages (from keras>=3.2.0->scikeras) (3.14.0)\n",
      "Requirement already satisfied: optree in c:\\users\\h_ale\\anaconda3\\envs\\cv\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.16.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\h_ale\\anaconda3\\envs\\cv\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\h_ale\\anaconda3\\envs\\cv\\lib\\site-packages (from keras>=3.2.0->scikeras) (24.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\h_ale\\anaconda3\\envs\\cv\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\h_ale\\anaconda3\\envs\\cv\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\h_ale\\anaconda3\\envs\\cv\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\h_ale\\anaconda3\\envs\\cv\\lib\\site-packages (from optree->keras>=3.2.0->scikeras) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\h_ale\\anaconda3\\envs\\cv\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\h_ale\\anaconda3\\envs\\cv\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\h_ale\\anaconda3\\envs\\cv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
      "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: scikeras\n",
      "Successfully installed scikeras-0.13.0\n"
     ]
    }
   ],
   "source": [
    "# Install essential packages\n",
    "# !pip install pandas\n",
    "# !pip install tensorflow\n",
    "# !pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd30c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd             \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, GlobalAveragePooling1D, Concatenate, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3abf91e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv(\"../data/cleaned_reddit_posts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2d0fa4",
   "metadata": {},
   "source": [
    "Show how many entries fall into each popularity bucket to understand class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e5f616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popularity_bucket\n",
      "high      3415\n",
      "low       3316\n",
      "medium    3316\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"popularity_bucket\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "45f1313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Drop unneeded columns\n",
    "df = df.drop(columns=[\"id\", \"author\", \"score\", \"num_comments\", \"upvote_ratio\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47334c41",
   "metadata": {},
   "source": [
    "Combine title and selftext to give the model more text information from the post, improving prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "683423f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Combine title and selftext\n",
    "df[\"text\"] = df[\"title\"].fillna('') + \" \" + df[\"selftext\"].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a8755b",
   "metadata": {},
   "source": [
    "This step encodes the target column popularity_bucket into integer labels using LabelEncoder.   \n",
    "The integer labels are then converted into one-hot vectors with to_categorical() for classification.   \n",
    "The final output y is a one-hot encoded target array used to train the model.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1e31a483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Encode labels (popularity_bucket)\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label\"] = label_encoder.fit_transform(df[\"popularity_bucket\"])\n",
    "y = to_categorical(df[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53822084",
   "metadata": {},
   "source": [
    "Prepare the text data for input into a neural network by converting it into numerical format.    \n",
    "First create a tokenizer that maps the most common 10,000 words to integers, treating unknown words as <OOV>.   \n",
    "Then it transforms each text into a sequence of integers and pads them to the same length (100) so the model can process them consistently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c8230af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Tokenize text\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df[\"text\"])\n",
    "sequences = tokenizer.texts_to_sequences(df[\"text\"])\n",
    "X_text = pad_sequences(sequences, maxlen=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90106acf",
   "metadata": {},
   "source": [
    "This code encodes categorical columns like \"subreddit\" using LabelEncoder after filling missing values.  \n",
    "It also converts binary and numeric features (like is_self, nsfw, and created_hour) into integer format.   \n",
    "Finally, all encoded features are combined into a single NumPy array X for model input, and the text features and other encoded features into a single input array for the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "abde45bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Encode categorical features\n",
    "cat_features = [\"subreddit\", \"flair\", \"media_type\"]\n",
    "encoded_features = []\n",
    "\n",
    "for col in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = df[col].fillna(\"unknown\")\n",
    "    encoded = le.fit_transform(df[col])\n",
    "    encoded_features.append(encoded)\n",
    "\n",
    "# Add binary features\n",
    "encoded_features.append(df[\"is_self\"].astype(int))\n",
    "encoded_features.append(df[\"nsfw\"].astype(int))\n",
    "encoded_features.append(df[\"created_hour\"].fillna(0).astype(int))\n",
    "\n",
    "# Final non-text input\n",
    "X_other = np.stack(encoded_features, axis=1)\n",
    "\n",
    "# horizontally join features into one array\n",
    "X_combined = np.hstack([X_text, X_other])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef21d59e",
   "metadata": {},
   "source": [
    "This function builds a Multilayer Perceptron (MLP) with three hidden layers and dropout for regularization.   \n",
    "It uses ReLU activation in hidden layers and softmax for multiclass output.    \n",
    "The model is compiled with Adam optimizer and categorical crossentropy loss for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b9e2ef64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Build the model\n",
    "def create_model(dropout_rate=0.3):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_combined.shape[1],)))  # single combined input\n",
    "    model.add(Dense(256, activation='relu'))  #128\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(128, activation='relu'))  #64\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b6f6a8",
   "metadata": {},
   "source": [
    "The dataset is split into training and testing sets to evaluate model performance.      \n",
    "A Keras model is wrapped and tuned using GridSearchCV to find the best hyperparameters.    \n",
    "The best model is then evaluated on the test set, and accuracy is calculated after converting predictions and labels from one-hot to class format.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dce4197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Compile and train\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Type of X_train:\", type(X_train))\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_train[0] shape:\", np.array(X_train[0]).shape)\n",
    "\n",
    "# Wrap model for GridSearch\n",
    "model = KerasClassifier(model=create_model, verbose=0)\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'batch_size': [16, 32],\n",
    "    'epochs': [20, 30],  #10, 15\n",
    "    \"model__dropout_rate\": [0.3, 0.5]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV on training data\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(f\"Best params: {grid_result.best_params_}\")\n",
    "print(f\"Best accuracy: {grid_result.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on unseen test data\n",
    "y_pred = grid_result.best_estimator_.predict(X_test)\n",
    "\n",
    "# Convert predictions to class labels if they are probabilities or one-hot\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)  \n",
    "\n",
    "# Convert one-hot y_test to class labels\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe86a95",
   "metadata": {},
   "source": [
    "Evaluate the model on the test set to get loss and accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "81cb70a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0994, Test accuracy: 0.3234\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "# Get the underlying Keras model from the best estimator\n",
    "best_model = grid_result.best_estimator_.model_\n",
    "\n",
    "# Evaluate on test data using combined features\n",
    "loss, accuracy = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test loss: {loss:.4f}, Test accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94528779",
   "metadata": {},
   "source": [
    "A detailed classification report and confusion matrix to evaluate model performance by comparing true and predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24692b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.32      1.00      0.49       650\n",
      "         low       0.00      0.00      0.00       684\n",
      "      medium       0.00      0.00      0.00       676\n",
      "\n",
      "    accuracy                           0.32      2010\n",
      "   macro avg       0.11      0.33      0.16      2010\n",
      "weighted avg       0.10      0.32      0.16      2010\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[650   0   0]\n",
      " [684   0   0]\n",
      " [676   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\h_ale\\anaconda3\\envs\\cv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\h_ale\\anaconda3\\envs\\cv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\h_ale\\anaconda3\\envs\\cv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_labels, y_pred_labels, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc92de",
   "metadata": {},
   "source": [
    "Calculate and display overall accuracy, precision, recall, and F1 score for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "beb0cf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Performance Metrics ===\n",
      "Accuracy:  0.3234\n",
      "Precision: 0.1046\n",
      "Recall:    0.3234\n",
      "F1 Score:  0.1580\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test set\n",
    "y_pred = grid_result.best_estimator_.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Compute metrics\n",
    "model_accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
    "model_precision = precision_score(y_test_labels, y_pred_labels, average='weighted', zero_division=0)\n",
    "model_recall = recall_score(y_test_labels, y_pred_labels, average='weighted', zero_division=0)\n",
    "model_f1 = f1_score(y_test_labels, y_pred_labels, average='weighted', zero_division=0)\n",
    "\n",
    "# Print all metrics\n",
    "print(\"\\n=== Model Performance Metrics ===\")\n",
    "print(f\"Accuracy:  {model_accuracy:.4f}\")\n",
    "print(f\"Precision: {model_precision:.4f}\")\n",
    "print(f\"Recall:    {model_recall:.4f}\")\n",
    "print(f\"F1 Score:  {model_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e244ca0",
   "metadata": {},
   "source": [
    "We will now train the model on a different subset of input features, to see if we can achieve better model performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
